# ========== TASK CONFIG ==========
env_name: real
device: cuda
num_envs: 25
max_episode_steps: 600
dataset_dir: /standard/liverobotics/dataset_corl_workshop/grasp_cup
image_latency_frame: 0
load_file: ${dataset_dir}/step_4999_action_pos.pth

# ========== OBS / ACTION STRUCTURE ==========
obs_keys: [gripper_image]
proprio_dim: 0
latent_dim: 0
obs_horizon: 1
pred_horizon: 16
action_horizon: 12
action_space: action_pos
action_dim: 9

# ========== DATASET ==========
dataset:
  _target_: CLASS.dataset.real.BCRealWorldDataset
  dataset_path: ${dataset_dir}/zarr
  num_demo: 40
  obs_keys: ${obs_keys}
  action_space: ${action_space}
  obs_horizon: ${obs_horizon}
  pred_horizon: ${pred_horizon}
  normalize_action_per_timestep: true
  device: cpu

# ========== POLICY ==========
policy:
  _target_: CLASS.agents.diffusion_policy.DiffusionPolicy
  obs_keys: ${obs_keys}
  proprio_dim: ${proprio_dim}
  latent_dim: ${latent_dim}
  action_dim: ${action_dim}
  obs_horizon: ${obs_horizon}
  pred_horizon: ${pred_horizon}
  vision_model: imn
  frozen_encoder: false
  spatial_softmax: true
  num_kp: 0
  device: ${device}
  num_inference_steps: 16

  model: 
    image_encoder:
      _target_: CLASS.model.vision.VisionEncoders
      vision_model: ${policy.vision_model}
      views: ${eval:"[key for key in ${policy.obs_keys} if 'image' in key]"}
      replace_norm: true
      spatial_softmax: ${policy.spatial_softmax}
      num_kp: ${policy.num_kp}
      noise_std: 0.001 
      frozen: ${policy.frozen_encoder}

    proprio_encoder:
      _target_: CLASS.model.MLP.MLP # torch.nn.Linear
      in_features: ${policy.proprio_dim}
      hidden_features: 128
      num_layers: -1
      out_features: ${policy.latent_dim}

    fusion_fn:
      _target_: CLASS.util.fusion.ConcatFusion

    policy_head:
      _target_: CLASS.model.unet1d.ConditionalUnet1D
      input_dim: ${action_dim}
      global_cond_dim: null
      diffusion_step_embed_dim: 256
      down_dims: [256, 512, 1024]
      kernel_size: 5
      n_groups: 8

  noise_scheduler:
    _target_: diffusers.schedulers.scheduling_ddpm.DDPMScheduler
    num_train_timesteps: 16
    beta_start: 0.0001
    beta_end: 0.02
    beta_schedule: squaredcos_cap_v2
    prediction_type: epsilon

# ========== TRAINING ==========
pretrain:
  num_epoch: 50
  train_bs: 160
  train_steps: null
  eval_steps: null

  optim:
    _target_: CLASS.util.optim.LARS
    lr: 0
    vision_lr: 0.4
    weight_decay: 1e-6

  scheduler:
    name: cosine
    num_warmup_steps: null

finetune:
  enabled: true # Set to true if you want to fine-tune with pretrained weights
  pretrain_policy_path: null # null if you want to use the latest trained model
  num_epoch: 500 
  train_bs: 64
  train_steps: null
  eval_steps: null

  optim:
    _target_: torch.optim.AdamW
    lr: 1e-4
    vision_lr: 1e-5
    weight_decay: 1e-6
    fused: true

  scheduler:
    name: cosine
    num_warmup_steps: 500


# ========== LOGGING ==========
wandb:
  name: ${env_name}_${now:%Y%m%d_%H%M%S}
  project: CLASS